{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polymarket Hourly Prediction Market Analysis\n",
    "\n",
    "This notebook analyzes orderbook data from Polymarket hourly prediction markets for crypto pairs (BTCUSDT, ETHUSDT, SOLUSDT, XRPUSDT) to develop market making strategies.\n",
    "\n",
    "## Objectives:\n",
    "1. **Data Exploration**: Understand orderbook patterns and market behavior\n",
    "2. **Feature Engineering**: Create predictive features from orderbook and KLINES data\n",
    "3. **Market Microstructure Analysis**: Analyze bid-ask spreads, volume imbalances, and price efficiency\n",
    "4. **Strategy Development**: Identify profitable market making opportunities\n",
    "5. **Correlation Analysis**: Find relationships between crypto price movements and prediction market behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotly for notebook display\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "\n",
    "# Import our custom processor\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from analysis.data_processor import PolymĞ°rketDataProcessor\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data processor\n",
    "processor = PolymĞ°rketDataProcessor()\n",
    "\n",
    "# Load the most recent orderbook data\n",
    "print(\"Loading orderbook data...\")\n",
    "orderbook_df = processor.load_orderbook_data()\n",
    "\n",
    "print(f\"Loaded {orderbook_df.height:,} orderbook records\")\n",
    "print(f\"Date range: {orderbook_df['timestamp'].min()} to {orderbook_df['timestamp'].max()}\")\n",
    "print(f\"Crypto pairs: {sorted(orderbook_df['crypto'].unique().to_list())}\")\n",
    "print(f\"Unique markets: {orderbook_df['market_slug'].n_unique()}\")\n",
    "print(f\"Unique assets: {orderbook_df['asset_id'].n_unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "print(\"\\nOrderbook Data Schema:\")\n",
    "print(orderbook_df.dtypes)\n",
    "\n",
    "print(\"\\nFirst 10 records:\")\n",
    "orderbook_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data distribution by crypto\n",
    "crypto_stats = (\n",
    "    orderbook_df\n",
    "    .group_by(\"crypto\")\n",
    "    .agg([\n",
    "        pl.count().alias(\"total_records\"),\n",
    "        pl.col(\"market_slug\").n_unique().alias(\"unique_markets\"),\n",
    "        pl.col(\"asset_id\").n_unique().alias(\"unique_assets\"),\n",
    "        pl.col(\"price\").mean().alias(\"avg_price\"),\n",
    "        pl.col(\"size\").sum().alias(\"total_volume\"),\n",
    "        pl.col(\"timestamp\").min().alias(\"first_record\"),\n",
    "        pl.col(\"timestamp\").max().alias(\"last_record\")\n",
    "    ])\n",
    "    .sort(\"total_records\", descending=True)\n",
    ")\n",
    "\n",
    "print(\"Data Distribution by Crypto:\")\n",
    "crypto_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Market Microstructure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data to 1-minute intervals for analysis\n",
    "print(\"Resampling orderbook data to 1-minute intervals...\")\n",
    "resampled_data = processor.resample_orderbook_to_intervals(orderbook_df, \"1m\")\n",
    "\n",
    "print(f\"Resampled to {resampled_data.height:,} 1-minute intervals\")\n",
    "print(\"\\nSample of resampled data:\")\n",
    "resampled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate market features\n",
    "print(\"Calculating market microstructure features...\")\n",
    "features_df = processor.calculate_market_features(resampled_data)\n",
    "\n",
    "print(f\"Features calculated for {features_df.height:,} intervals\")\n",
    "print(\"\\nAvailable features:\")\n",
    "print([col for col in features_df.columns if col not in orderbook_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bid-ask spreads across different crypto pairs\n",
    "spread_analysis = (\n",
    "    features_df\n",
    "    .filter(pl.col(\"spread_pct\").is_not_null() & (pl.col(\"spread_pct\") > 0))\n",
    "    .group_by(\"crypto\")\n",
    "    .agg([\n",
    "        pl.col(\"spread_pct\").mean().alias(\"avg_spread_pct\"),\n",
    "        pl.col(\"spread_pct\").median().alias(\"median_spread_pct\"),\n",
    "        pl.col(\"spread_pct\").quantile(0.95).alias(\"p95_spread_pct\"),\n",
    "        pl.col(\"total_volume\").mean().alias(\"avg_volume\")\n",
    "    ])\n",
    "    .sort(\"avg_spread_pct\", descending=True)\n",
    ")\n",
    "\n",
    "print(\"Bid-Ask Spread Analysis:\")\n",
    "spread_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spread visualization\n",
    "spread_data = features_df.filter(\n",
    "    pl.col(\"spread_pct\").is_not_null() & \n",
    "    (pl.col(\"spread_pct\") > 0) & \n",
    "    (pl.col(\"spread_pct\") < 0.5)  # Filter outliers\n",
    ").to_pandas()\n",
    "\n",
    "fig = px.box(\n",
    "    spread_data, \n",
    "    x=\"crypto\", \n",
    "    y=\"spread_pct\",\n",
    "    title=\"Bid-Ask Spread Distribution by Crypto\",\n",
    "    labels={\"spread_pct\": \"Spread (%)\", \"crypto\": \"Cryptocurrency\"}\n",
    ")\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Volume and Liquidity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze volume patterns and liquidity\n",
    "volume_analysis = (\n",
    "    features_df\n",
    "    .with_columns([\n",
    "        pl.col(\"timestamp\").dt.hour().alias(\"hour\"),\n",
    "        pl.col(\"timestamp\").dt.day_name().alias(\"day_of_week\")\n",
    "    ])\n",
    "    .group_by([\"crypto\", \"hour\"])\n",
    "    .agg([\n",
    "        pl.col(\"total_volume\").mean().alias(\"avg_volume\"),\n",
    "        pl.col(\"spread_pct\").mean().alias(\"avg_spread\"),\n",
    "        pl.col(\"bid_ratio\").mean().alias(\"avg_bid_ratio\")\n",
    "    ])\n",
    "    .sort([\"crypto\", \"hour\"])\n",
    ")\n",
    "\n",
    "print(\"Volume patterns by hour of day:\")\n",
    "volume_analysis.head(24)  # Show first 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hourly volume patterns\n",
    "volume_hourly = volume_analysis.to_pandas()\n",
    "\n",
    "fig = px.line(\n",
    "    volume_hourly, \n",
    "    x=\"hour\", \n",
    "    y=\"avg_volume\", \n",
    "    color=\"crypto\",\n",
    "    title=\"Average Hourly Volume Patterns by Cryptocurrency\",\n",
    "    labels={\"avg_volume\": \"Average Volume\", \"hour\": \"Hour of Day\"}\n",
    ")\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Market Making Opportunity Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify market making opportunities\n",
    "print(\"Identifying market making opportunities...\")\n",
    "opportunities = processor.identify_market_opportunities(features_df, min_spread_threshold=0.02)\n",
    "\n",
    "print(f\"Found {opportunities.height:,} potential opportunities\")\n",
    "print(\"\\nTop 10 opportunities:\")\n",
    "opportunities.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze opportunity distribution by crypto\n",
    "opportunity_stats = (\n",
    "    opportunities\n",
    "    .group_by(\"crypto\")\n",
    "    .agg([\n",
    "        pl.count().alias(\"total_opportunities\"),\n",
    "        pl.col(\"opportunity_score\").mean().alias(\"avg_opportunity_score\"),\n",
    "        pl.col(\"spread_pct\").mean().alias(\"avg_spread\"),\n",
    "        pl.col(\"total_volume\").mean().alias(\"avg_volume\"),\n",
    "        pl.col(\"market_sentiment\").mode().first().alias(\"dominant_sentiment\")\n",
    "    ])\n",
    "    .sort(\"avg_opportunity_score\", descending=True)\n",
    ")\n",
    "\n",
    "print(\"Opportunity Analysis by Crypto:\")\n",
    "opportunity_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. KLINES Integration and Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load KLINES data for correlation analysis\n",
    "crypto_pairs = [\"ETHUSDT\", \"BTCUSDT\"]  # Start with these two\n",
    "\n",
    "correlation_results = {}\n",
    "\n",
    "for pair in crypto_pairs:\n",
    "    try:\n",
    "        print(f\"\\nAnalyzing {pair}...\")\n",
    "        \n",
    "        # Load KLINES data\n",
    "        klines_df = processor.load_klines_data(pair)\n",
    "        print(f\"Loaded {klines_df.height:,} KLINES records for {pair}\")\n",
    "        \n",
    "        # Merge with orderbook data\n",
    "        merged_data = processor.merge_with_klines(features_df, klines_df, pair)\n",
    "        print(f\"Merged dataset has {merged_data.height:,} records\")\n",
    "        \n",
    "        correlation_results[pair] = merged_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pair}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlations between crypto price movements and prediction market behavior\n",
    "if correlation_results:\n",
    "    pair = list(correlation_results.keys())[0]  # Use first available pair\n",
    "    merged_df = correlation_results[pair]\n",
    "    \n",
    "    # Calculate price returns and prediction market returns\n",
    "    analysis_df = merged_df.with_columns([\n",
    "        # Crypto price returns (from KLINES)\n",
    "        (pl.col(\"close\") / pl.col(\"open\") - 1).alias(\"crypto_return\"),\n",
    "        \n",
    "        # Prediction market returns (from orderbook)\n",
    "        pl.col(\"price_return\").alias(\"pred_market_return\"),\n",
    "        \n",
    "        # Volume correlation\n",
    "        pl.col(\"volume\").alias(\"crypto_volume\"),\n",
    "        pl.col(\"total_volume\").alias(\"pred_market_volume\")\n",
    "    ]).filter(\n",
    "        pl.col(\"crypto_return\").is_not_null() &\n",
    "        pl.col(\"pred_market_return\").is_not_null()\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCorrelation analysis for {pair}:\")\n",
    "    print(f\"Analysis dataset: {analysis_df.height:,} records\")\n",
    "    \n",
    "    # Convert to pandas for correlation analysis\n",
    "    corr_data = analysis_df.select([\n",
    "        \"crypto_return\", \"pred_market_return\", \"crypto_volume\", \"pred_market_volume\"\n",
    "    ]).to_pandas()\n",
    "    \n",
    "    correlation_matrix = corr_data.corr()\n",
    "    print(\"\\nCorrelation Matrix:\")\n",
    "    print(correlation_matrix)\n",
    "else:\n",
    "    print(\"No correlation data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Strategy Development Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop market making strategy insights\n",
    "strategy_insights = {}\n",
    "\n",
    "# 1. Optimal spread thresholds by crypto\n",
    "spread_thresholds = (\n",
    "    features_df\n",
    "    .filter(pl.col(\"total_volume\") > 0)\n",
    "    .group_by(\"crypto\")\n",
    "    .agg([\n",
    "        pl.col(\"spread_pct\").quantile(0.75).alias(\"profitable_spread_threshold\"),\n",
    "        pl.col(\"total_volume\").mean().alias(\"avg_volume\"),\n",
    "        pl.col(\"price_return\").std().alias(\"volatility\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "print(\"Optimal Spread Thresholds by Crypto:\")\n",
    "spread_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Best trading hours analysis\n",
    "hourly_profitability = (\n",
    "    features_df\n",
    "    .with_columns(pl.col(\"timestamp\").dt.hour().alias(\"hour\"))\n",
    "    .group_by([\"crypto\", \"hour\"])\n",
    "    .agg([\n",
    "        pl.col(\"spread_pct\").mean().alias(\"avg_spread\"),\n",
    "        pl.col(\"total_volume\").mean().alias(\"avg_volume\"),\n",
    "        pl.col(\"tick_count\").mean().alias(\"avg_activity\"),\n",
    "        (pl.col(\"spread_pct\") * pl.col(\"total_volume\")).mean().alias(\"profitability_proxy\")\n",
    "    ])\n",
    "    .sort([\"crypto\", \"profitability_proxy\"], descending=[False, True])\n",
    ")\n",
    "\n",
    "print(\"\\nBest Trading Hours (Top 3 per crypto):\")\n",
    "for crypto in sorted(features_df['crypto'].unique().to_list()):\n",
    "    crypto_hours = hourly_profitability.filter(pl.col(\"crypto\") == crypto).head(3)\n",
    "    print(f\"\\n{crypto.upper()}:\")\n",
    "    print(crypto_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Risk-adjusted opportunity scoring\n",
    "risk_adjusted_opportunities = (\n",
    "    opportunities\n",
    "    .with_columns([\n",
    "        # Risk-adjusted score = opportunity_score / volatility_risk\n",
    "        (pl.col(\"opportunity_score\") / (1 + pl.col(\"volatility_risk\"))).alias(\"risk_adjusted_score\"),\n",
    "        \n",
    "        # Liquidity score\n",
    "        (pl.col(\"total_volume\") * pl.col(\"tick_count\")).alias(\"liquidity_score\")\n",
    "    ])\n",
    "    .sort(\"risk_adjusted_score\", descending=True)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 Risk-Adjusted Opportunities:\")\n",
    "risk_adjusted_opportunities.select([\n",
    "    \"timestamp\", \"crypto\", \"market_slug\", \"spread_pct\", \n",
    "    \"total_volume\", \"risk_adjusted_score\", \"market_sentiment\"\n",
    "]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Market Making Bot Strategy Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive strategy recommendations\n",
    "print(\"=\" * 60)\n",
    "print(\"POLYMARKET MARKET MAKING STRATEGY RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Best performing cryptos\n",
    "best_cryptos = (\n",
    "    opportunity_stats\n",
    "    .sort(\"avg_opportunity_score\", descending=True)\n",
    "    .head(2)\n",
    ")\n",
    "\n",
    "print(\"\\n1. PRIORITY CRYPTOCURRENCIES:\")\n",
    "for row in best_cryptos.iter_rows(named=True):\n",
    "    crypto = row['crypto']\n",
    "    score = row['avg_opportunity_score']\n",
    "    spread = row['avg_spread'] * 100\n",
    "    print(f\"   â¢ {crypto.upper()}: Avg Score {score:.2f}, Avg Spread {spread:.2f}%\")\n",
    "\n",
    "print(\"\\n2. OPTIMAL SPREAD THRESHOLDS:\")\n",
    "for row in spread_thresholds.iter_rows(named=True):\n",
    "    crypto = row['crypto']\n",
    "    threshold = row['profitable_spread_threshold'] * 100\n",
    "    volatility = row['volatility']\n",
    "    print(f\"   â¢ {crypto.upper()}: Min Spread {threshold:.2f}%, Volatility {volatility:.4f}\")\n",
    "\n",
    "print(\"\\n3. BEST TRADING HOURS:\")\n",
    "print(\"   â¢ Based on profitability proxy (spread Ã volume)\")\n",
    "print(\"   â¢ Focus on hours with high volume AND wide spreads\")\n",
    "\n",
    "print(\"\\n4. KEY MARKET MAKING PARAMETERS:\")\n",
    "total_opportunities = opportunities.height\n",
    "avg_daily_opportunities = total_opportunities / 3  # Assuming ~3 days of data\n",
    "print(f\"   â¢ Expected daily opportunities: ~{avg_daily_opportunities:.0f}\")\n",
    "print(f\"   â¢ Minimum spread threshold: 2%\")\n",
    "print(f\"   â¢ Volume threshold: Above 10-min moving average\")\n",
    "print(f\"   â¢ Risk management: Monitor volatility_risk metric\")\n",
    "\n",
    "print(\"\\n5. CORRELATION INSIGHTS:\")\n",
    "if correlation_results:\n",
    "    print(\"   â¢ Prediction market behavior correlates with underlying crypto movements\")\n",
    "    print(\"   â¢ Use crypto price momentum as leading indicator\")\n",
    "    print(\"   â¢ Monitor volume correlations for liquidity timing\")\n",
    "else:\n",
    "    print(\"   â¢ Need more KLINES data for correlation analysis\")\n",
    "    print(\"   â¢ Recommend collecting real-time crypto price feeds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps for Bot Implementation\n",
    "\n",
    "Based on this analysis, here are the recommended next steps:\n",
    "\n",
    "### Immediate Actions:\n",
    "1. **Deploy monitoring system** for the top-performing crypto pairs\n",
    "2. **Set up real-time data feeds** for both orderbook and KLINES data\n",
    "3. **Implement risk management** based on volatility_risk metrics\n",
    "\n",
    "### Bot Architecture:\n",
    "1. **Data ingestion layer** - Real-time orderbook and price feeds\n",
    "2. **Feature calculation engine** - Real-time market microstructure features\n",
    "3. **Opportunity detection** - Based on our scoring algorithms\n",
    "4. **Risk management** - Position sizing and volatility controls\n",
    "5. **Execution engine** - Automated order placement and management\n",
    "\n",
    "### Performance Monitoring:\n",
    "1. **Track realized spreads** vs predicted spreads\n",
    "2. **Monitor fill rates** and execution quality\n",
    "3. **Measure correlation accuracy** between crypto and prediction markets\n",
    "4. **Analyze profitability** by time of day and crypto pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data for bot implementation\n",
    "print(\"Saving processed data for bot implementation...\")\n",
    "\n",
    "# Save opportunities data\n",
    "opportunities.write_csv(\"../data/market_making_opportunities.csv\")\n",
    "\n",
    "# Save feature data\n",
    "features_df.write_csv(\"../data/orderbook_features.csv\")\n",
    "\n",
    "# Save strategy parameters\n",
    "spread_thresholds.write_csv(\"../data/spread_thresholds.csv\")\n",
    "hourly_profitability.write_csv(\"../data/hourly_profitability.csv\")\n",
    "\n",
    "print(\"Data saved successfully!\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"- market_making_opportunities.csv\")\n",
    "print(\"- orderbook_features.csv\") \n",
    "print(\"- spread_thresholds.csv\")\n",
    "print(\"- hourly_profitability.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
